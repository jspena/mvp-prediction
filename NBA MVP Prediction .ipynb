{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the NBA Regular Season MVP using player statistics and machine learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup and Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries \n",
    "import numpy as np # Linear algebra package\n",
    "import pandas as pd # Data processing and dataframe structure\n",
    "import matplotlib.pyplot as plt # plotting package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvp_votes = pd.read_csv('mvp_votings.csv', index_col = 0)\n",
    "test_data = pd.read_csv('test_data.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fga</th>\n",
       "      <th>fg3a</th>\n",
       "      <th>fta</th>\n",
       "      <th>per</th>\n",
       "      <th>ts_pct</th>\n",
       "      <th>usg_pct</th>\n",
       "      <th>bpm</th>\n",
       "      <th>season</th>\n",
       "      <th>player</th>\n",
       "      <th>win_pct</th>\n",
       "      <th>...</th>\n",
       "      <th>pts_per_g</th>\n",
       "      <th>trb_per_g</th>\n",
       "      <th>ast_per_g</th>\n",
       "      <th>stl_per_g</th>\n",
       "      <th>blk_per_g</th>\n",
       "      <th>fg_pct</th>\n",
       "      <th>fg3_pct</th>\n",
       "      <th>ft_pct</th>\n",
       "      <th>ws</th>\n",
       "      <th>ws_per_48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>6.5</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.572</td>\n",
       "      <td>28.4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1980-81</td>\n",
       "      <td>Julius Erving</td>\n",
       "      <td>0.756098</td>\n",
       "      <td>...</td>\n",
       "      <td>24.6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.787</td>\n",
       "      <td>13.8</td>\n",
       "      <td>0.231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.9</td>\n",
       "      <td>0.528</td>\n",
       "      <td>24.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1980-81</td>\n",
       "      <td>Larry Bird</td>\n",
       "      <td>0.756098</td>\n",
       "      <td>...</td>\n",
       "      <td>21.2</td>\n",
       "      <td>10.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.478</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.863</td>\n",
       "      <td>10.8</td>\n",
       "      <td>0.160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>25.5</td>\n",
       "      <td>0.616</td>\n",
       "      <td>26.3</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1980-81</td>\n",
       "      <td>Kareem Abdul-Jabbar</td>\n",
       "      <td>0.658537</td>\n",
       "      <td>...</td>\n",
       "      <td>26.2</td>\n",
       "      <td>10.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.766</td>\n",
       "      <td>14.3</td>\n",
       "      <td>0.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.585</td>\n",
       "      <td>27.6</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1980-81</td>\n",
       "      <td>Moses Malone</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>...</td>\n",
       "      <td>27.8</td>\n",
       "      <td>14.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.757</td>\n",
       "      <td>13.7</td>\n",
       "      <td>0.202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>7.6</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.555</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1980-81</td>\n",
       "      <td>George Gervin</td>\n",
       "      <td>0.634146</td>\n",
       "      <td>...</td>\n",
       "      <td>27.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.826</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    fga  fg3a   fta   per  ts_pct  usg_pct  bpm   season               player  \\\n",
       "0  18.6   0.2   6.5  25.1   0.572     28.4  8.0  1980-81        Julius Erving   \n",
       "1  18.3   0.9   4.0  19.9   0.528     24.3  5.1  1980-81           Larry Bird   \n",
       "2  18.2   0.0   6.9  25.5   0.616     26.3  5.3  1980-81  Kareem Abdul-Jabbar   \n",
       "3  19.3   0.0  10.1  25.1   0.585     27.6  3.7  1980-81         Moses Malone   \n",
       "4  21.1   0.4   7.6  22.9   0.555     32.3  1.6  1980-81        George Gervin   \n",
       "\n",
       "    win_pct  ...  pts_per_g  trb_per_g  ast_per_g  stl_per_g  blk_per_g  \\\n",
       "0  0.756098  ...       24.6        8.0        4.4        2.1        1.8   \n",
       "1  0.756098  ...       21.2       10.9        5.5        2.0        0.8   \n",
       "2  0.658537  ...       26.2       10.3        3.4        0.7        2.9   \n",
       "3  0.487805  ...       27.8       14.8        1.8        1.0        1.9   \n",
       "4  0.634146  ...       27.1        5.1        3.2        1.1        0.7   \n",
       "\n",
       "   fg_pct  fg3_pct  ft_pct    ws  ws_per_48  \n",
       "0   0.521    0.222   0.787  13.8      0.231  \n",
       "1   0.478    0.270   0.863  10.8      0.160  \n",
       "2   0.574    0.000   0.766  14.3      0.230  \n",
       "3   0.522    0.333   0.757  13.7      0.202  \n",
       "4   0.492    0.257   0.826  10.5      0.182  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mvp_votes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fga</th>\n",
       "      <th>fg3a</th>\n",
       "      <th>fta</th>\n",
       "      <th>per</th>\n",
       "      <th>ts_pct</th>\n",
       "      <th>usg_pct</th>\n",
       "      <th>bpm</th>\n",
       "      <th>player</th>\n",
       "      <th>win_pct</th>\n",
       "      <th>g</th>\n",
       "      <th>...</th>\n",
       "      <th>pts_per_g</th>\n",
       "      <th>trb_per_g</th>\n",
       "      <th>ast_per_g</th>\n",
       "      <th>stl_per_g</th>\n",
       "      <th>blk_per_g</th>\n",
       "      <th>fg_pct</th>\n",
       "      <th>fg3_pct</th>\n",
       "      <th>ft_pct</th>\n",
       "      <th>ws</th>\n",
       "      <th>ws_per_48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.5</td>\n",
       "      <td>13.2</td>\n",
       "      <td>11.0</td>\n",
       "      <td>30.6</td>\n",
       "      <td>0.616</td>\n",
       "      <td>40.5</td>\n",
       "      <td>11.7</td>\n",
       "      <td>James Harden</td>\n",
       "      <td>0.646341</td>\n",
       "      <td>78</td>\n",
       "      <td>...</td>\n",
       "      <td>36.1</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.879</td>\n",
       "      <td>15.2</td>\n",
       "      <td>0.254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>9.5</td>\n",
       "      <td>30.9</td>\n",
       "      <td>0.644</td>\n",
       "      <td>32.3</td>\n",
       "      <td>10.8</td>\n",
       "      <td>Giannis Antetokounmpo</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>72</td>\n",
       "      <td>...</td>\n",
       "      <td>27.7</td>\n",
       "      <td>12.5</td>\n",
       "      <td>5.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.729</td>\n",
       "      <td>14.4</td>\n",
       "      <td>0.292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>24.6</td>\n",
       "      <td>0.682</td>\n",
       "      <td>17.8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Rudy Gobert</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>81</td>\n",
       "      <td>...</td>\n",
       "      <td>15.9</td>\n",
       "      <td>12.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.669</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.636</td>\n",
       "      <td>14.4</td>\n",
       "      <td>0.268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>23.7</td>\n",
       "      <td>0.588</td>\n",
       "      <td>29.3</td>\n",
       "      <td>5.5</td>\n",
       "      <td>Damian Lillard</td>\n",
       "      <td>0.646341</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>25.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>6.9</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.912</td>\n",
       "      <td>12.1</td>\n",
       "      <td>0.205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.0</td>\n",
       "      <td>9.8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.583</td>\n",
       "      <td>29.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>Paul George</td>\n",
       "      <td>0.597561</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>8.2</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.839</td>\n",
       "      <td>11.9</td>\n",
       "      <td>0.201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    fga  fg3a   fta   per  ts_pct  usg_pct   bpm                 player  \\\n",
       "0  24.5  13.2  11.0  30.6   0.616     40.5  11.7           James Harden   \n",
       "1  17.3   2.8   9.5  30.9   0.644     32.3  10.8  Giannis Antetokounmpo   \n",
       "2   8.8   0.0   6.4  24.6   0.682     17.8   7.0            Rudy Gobert   \n",
       "3  19.2   8.0   6.4  23.7   0.588     29.3   5.5         Damian Lillard   \n",
       "4  21.0   9.8   7.0  23.3   0.583     29.5   5.5            Paul George   \n",
       "\n",
       "    win_pct   g  ...  pts_per_g  trb_per_g  ast_per_g  stl_per_g  blk_per_g  \\\n",
       "0  0.646341  78  ...       36.1        6.6        7.5        2.0        0.7   \n",
       "1  0.731707  72  ...       27.7       12.5        5.9        1.3        1.5   \n",
       "2  0.609756  81  ...       15.9       12.9        2.0        0.8        2.3   \n",
       "3  0.646341  80  ...       25.8        4.6        6.9        1.1        0.4   \n",
       "4  0.597561  77  ...       28.0        8.2        4.1        2.2        0.4   \n",
       "\n",
       "   fg_pct  fg3_pct  ft_pct    ws  ws_per_48  \n",
       "0   0.442    0.368   0.879  15.2      0.254  \n",
       "1   0.578    0.256   0.729  14.4      0.292  \n",
       "2   0.669      NaN   0.636  14.4      0.268  \n",
       "3   0.444    0.369   0.912  12.1      0.205  \n",
       "4   0.438    0.386   0.839  11.9      0.201  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting variables for model and target variable\n",
    "y = mvp_votes['points_won'] # target variable set as number of votes awarded to player\n",
    "y_2 = mvp_votes['award_share'] # target variable set as share of total votes \n",
    "\n",
    "features = ['fga', 'fg3a', 'fta', 'per', 'ts_pct', 'usg_pct', 'bpm', 'win_pct',\n",
    "           'g', 'mp_per_g', 'pts_per_g', 'trb_per_g', 'ast_per_g', 'stl_per_g',\n",
    "           'blk_per_g', 'fg_pct', 'fg3_pct', 'ft_pct', 'ws_per_48']\n",
    "x = mvp_votes[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building functions to make models reproducible over many interations\n",
    "# Models to be built: Random Forest Regressor, Neural Net, and Stochastic Gradient Descent Regressor\n",
    "\n",
    "# Random Forest Regressor model function\n",
    "def mse_random_forest(num_estimators, x_train, y_train, x_test, y_test):\n",
    "    rfr = RandomForestRegressor(n_estimators=num_estimators, \n",
    "                                random_state=1)\n",
    "    rfr.fit(x_train, y_train)\n",
    "    y_pred = rfr.predict(x_test)\n",
    "    return mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Neural Net model function\n",
    "def mse_multi_layer_perceptron(num_hidden_layers, alpha_used, x_train, y_train, x_test, y_test):\n",
    "    nn = MLPRegressor(solver='lbfgs', \n",
    "                      hidden_layer_sizes=num_hidden_layers, \n",
    "                      alpha=alpha_used,\n",
    "                      random_state=1)\n",
    "    nn.fit(x_train, y_train)\n",
    "    y_pred = nn.predict(x_test)\n",
    "    return mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Stochastic Gradient Descent model function\n",
    "def mse_sgd(iterations, alpha_used, x_train, y_train, x_test, y_test):\n",
    "    sgd = SGDRegressor(max_iter=iterations,\n",
    "                       alpha=alpha_used)\n",
    "    sgd.fit(x_train, y_train)\n",
    "    y_pred = sgd.predict(x_test)\n",
    "    return mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for modeling and evaluation\n",
    "from sklearn.model_selection import train_test_split # Splits data into training and test sets\n",
    "from sklearn import preprocessing # Data scaling\n",
    "\n",
    "# Scaling data to have a mean of 0 and variance of 1\n",
    "x_scaled = preprocessing.scale(x)\n",
    "\n",
    "# Split data into training and test sets for points won and award share\n",
    "# Points won split\n",
    "x_train_pw, x_test_pw, y_train_pw, y_test_pw = train_test_split(x_scaled,\n",
    "                                                                y, \n",
    "                                                                random_state=1)\n",
    "# Award share split\n",
    "x_train_as, x_test_as, y_train_as, y_test_as = train_test_split(x_scaled,\n",
    "                                                                y_2,\n",
    "                                                                random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting Total Votes for MVP candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Models Performance (Points Won)\n",
      "Estimator:  50  | Mean Squared Error:  29764.489731\n",
      "Estimator:  100  | Mean Squared Error:  29760.241289531252\n",
      "Estimator:  200  | Mean Squared Error:  30443.393080443748\n",
      "Estimator:  500  | Mean Squared Error:  30984.786461582\n",
      "Estimator:  1000  | Mean Squared Error:  30916.18229113987\n",
      "------------------------------------------------------------- \n",
      "\n",
      "Neural Network Models Performance (Points Won)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer size:  50  | Alpha:  0.0001  | Mean Squared Error:  63869.53103226186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer size:  50  | Alpha:  0.0003  | Mean Squared Error:  64989.38179178904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer size:  50  | Alpha:  0.001  | Mean Squared Error:  63248.90290315335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer size:  50  | Alpha:  0.003  | Mean Squared Error:  63357.02565881738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer size:  100  | Alpha:  0.0001  | Mean Squared Error:  84975.7455777672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer size:  100  | Alpha:  0.0003  | Mean Squared Error:  84424.67884960308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer size:  100  | Alpha:  0.001  | Mean Squared Error:  85318.69385057315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer size:  100  | Alpha:  0.003  | Mean Squared Error:  80972.73037634941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer size:  150  | Alpha:  0.0001  | Mean Squared Error:  78247.42958371571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer size:  150  | Alpha:  0.0003  | Mean Squared Error:  86510.94556350268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer size:  150  | Alpha:  0.001  | Mean Squared Error:  70198.79105279702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer size:  150  | Alpha:  0.003  | Mean Squared Error:  68730.38079890369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer size:  200  | Alpha:  0.0001  | Mean Squared Error:  63396.33497700896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer size:  200  | Alpha:  0.0003  | Mean Squared Error:  72090.02686316252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer size:  200  | Alpha:  0.001  | Mean Squared Error:  64301.62722573796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer size:  200  | Alpha:  0.003  | Mean Squared Error:  65589.81481459731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer size:  250  | Alpha:  0.0001  | Mean Squared Error:  68191.8394860422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer size:  250  | Alpha:  0.0003  | Mean Squared Error:  65704.83572020747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer size:  250  | Alpha:  0.001  | Mean Squared Error:  68117.77107412383\n",
      "Layer size:  250  | Alpha:  0.003  | Mean Squared Error:  61989.268525916814\n",
      "------------------------------------------------------------- \n",
      "\n",
      "Stochastic Gradient Descent Models Performance (Points Won)\n",
      "Maximum iterations:  500  | Alpha:  0.0001  | Mean Squared Error:  35304.14454803249\n",
      "Maximum iterations:  500  | Alpha:  0.0003  | Mean Squared Error:  35076.283900752154\n",
      "Maximum iterations:  500  | Alpha:  0.001  | Mean Squared Error:  35869.980175415694\n",
      "Maximum iterations:  500  | Alpha:  0.003  | Mean Squared Error:  35485.192503313825\n",
      "Maximum iterations:  1000  | Alpha:  0.0001  | Mean Squared Error:  35076.31140093242\n",
      "Maximum iterations:  1000  | Alpha:  0.0003  | Mean Squared Error:  35176.16990043975\n",
      "Maximum iterations:  1000  | Alpha:  0.001  | Mean Squared Error:  35723.32861837968\n",
      "Maximum iterations:  1000  | Alpha:  0.003  | Mean Squared Error:  35015.62639237775\n",
      "Maximum iterations:  1500  | Alpha:  0.0001  | Mean Squared Error:  34790.53743067102\n",
      "Maximum iterations:  1500  | Alpha:  0.0003  | Mean Squared Error:  35688.77290905763\n",
      "Maximum iterations:  1500  | Alpha:  0.001  | Mean Squared Error:  35634.74877084249\n",
      "Maximum iterations:  1500  | Alpha:  0.003  | Mean Squared Error:  35015.35710732198\n",
      "Maximum iterations:  2000  | Alpha:  0.0001  | Mean Squared Error:  35582.113310673856\n",
      "Maximum iterations:  2000  | Alpha:  0.0003  | Mean Squared Error:  35106.7834634547\n",
      "Maximum iterations:  2000  | Alpha:  0.001  | Mean Squared Error:  35478.08691263218\n",
      "Maximum iterations:  2000  | Alpha:  0.003  | Mean Squared Error:  35134.75364655224\n",
      "Maximum iterations:  2500  | Alpha:  0.0001  | Mean Squared Error:  35595.825521050254\n",
      "Maximum iterations:  2500  | Alpha:  0.0003  | Mean Squared Error:  35969.55462458289\n",
      "Maximum iterations:  2500  | Alpha:  0.001  | Mean Squared Error:  34433.748566739356\n",
      "Maximum iterations:  2500  | Alpha:  0.003  | Mean Squared Error:  34963.808296636926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "# Import libraries for modeling and evaluation\n",
    "from sklearn.linear_model import SGDRegressor # Stochastic Gradient Descent\n",
    "from sklearn.ensemble import RandomForestRegressor # Random Forest\n",
    "from sklearn.neural_network import MLPRegressor # Multi-layer perceptron network\n",
    "from sklearn.metrics import mean_squared_error # Metric used for model evaluation\n",
    "\n",
    "# Testing for best combination of parameters for Random Forest model\n",
    "estimators = [50, 100, 200, 500, 1000]\n",
    "print(\"Random Forest Models Performance (Points Won)\")\n",
    "for num_estimators in estimators:\n",
    "    print('Estimator: ', num_estimators, ' | Mean Squared Error: ', mse_random_forest(num_estimators, \n",
    "                                                                                      x_train_pw,\n",
    "                                                                                      y_train_pw, \n",
    "                                                                                      x_test_pw, \n",
    "                                                                                      y_test_pw))\n",
    "    \n",
    "print('-------------------------------------------------------------', '\\n')\n",
    "\n",
    "# Testing for best combination of parameters for Neural Network model\n",
    "layers = [50, 100, 150, 200, 250]\n",
    "alpha_test = [0.0001, 0.0003, 0.001, 0.003]\n",
    "print('Neural Network Models Performance (Points Won)')\n",
    "for num_hidden_layers in layers:\n",
    "    for alpha_used in alpha_test:\n",
    "        print('Layer size: ', num_hidden_layers, ' | Alpha: ', alpha_used, ' | Mean Squared Error: ',\n",
    "              mse_multi_layer_perceptron(num_hidden_layers, \n",
    "                                         alpha_used, \n",
    "                                         x_train_pw, \n",
    "                                         y_train_pw, \n",
    "                                         x_test_pw, \n",
    "                                         y_test_pw))\n",
    "        \n",
    "print('-------------------------------------------------------------', '\\n')\n",
    "\n",
    "# Testing for best combination of parameters for Stochastic Gradient Descent model\n",
    "max_iterations = [500, 1000, 1500, 2000, 2500]\n",
    "print('Stochastic Gradient Descent Models Performance (Points Won)')\n",
    "for iterations in max_iterations:\n",
    "    for alpha_used in alpha_test:\n",
    "        print('Maximum iterations: ', iterations, ' | Alpha: ', alpha_used, ' | Mean Squared Error: ',\n",
    "              mse_sgd(iterations,\n",
    "                      alpha_used, \n",
    "                      x_train_pw, \n",
    "                      y_train_pw, \n",
    "                      x_test_pw,\n",
    "                      y_test_pw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.003, average=False, early_stopping=False, epsilon=0.1,\n",
       "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
       "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=None,\n",
       "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting best models for each method\n",
    "# Random Forest Regressor\n",
    "best_rfr_pw = RandomForestRegressor(n_estimators=100, random_state=1)\n",
    "best_rfr_pw.fit(x_train_pw, y_train_pw)\n",
    "\n",
    "# Neural Network\n",
    "best_nn_pw = MLPRegressor(solver='lbfgs', hidden_layer_sizes=250, alpha=0.003, random_state=1)\n",
    "best_nn_pw.fit(x_train_pw, y_train_pw)\n",
    "\n",
    "# Stochastic Gradient Descent\n",
    "best_sgd_pw = SGDRegressor(max_iter=1000, alpha=0.003)\n",
    "best_sgd_pw.fit(x_train_pw, y_train_pw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the test data to fill in NA values with 0 before applying models\n",
    "test_data['fg3_pct'] = test_data['fg3_pct'].fillna(value = 0)\n",
    "\n",
    "# Scale test data \n",
    "test_data_scaled = preprocessing.scale(test_data[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   player  Random Forest Points Predictions  \\\n",
      "1   Giannis Antetokounmpo                           998.000   \n",
      "0            James Harden                           842.160   \n",
      "3          Damian Lillard                           654.610   \n",
      "12          Kawhi Leonard                           633.190   \n",
      "5            Nikola Jokic                           622.370   \n",
      "6            Kevin Durant                           618.760   \n",
      "11          Stephen Curry                           617.570   \n",
      "18            Joel Embiid                           367.960   \n",
      "2             Rudy Gobert                           339.559   \n",
      "4             Paul George                           338.400   \n",
      "7            Clint Capela                           295.035   \n",
      "38      Russell Westbrook                           220.235   \n",
      "10         Andre Drummond                           189.860   \n",
      "9          Nikola Vucevic                           182.396   \n",
      "8      Karl-Anthony Towns                           171.281   \n",
      "32           Kemba Walker                           169.350   \n",
      "26           Jusuf Nurkic                           131.870   \n",
      "15           Kyrie Irving                           112.960   \n",
      "14      LaMarcus Aldridge                            91.800   \n",
      "17       Montrezl Harrell                            89.965   \n",
      "21           Eric Bledsoe                            56.210   \n",
      "29           Bradley Beal                            55.840   \n",
      "25         Derrick Favors                            41.090   \n",
      "20            Ben Simmons                            35.455   \n",
      "23            Mike Conley                            32.560   \n",
      "22          Blake Griffin                            28.660   \n",
      "19       Danilo Gallinari                            26.235   \n",
      "24           Jimmy Butler                            25.975   \n",
      "13          Pascal Siakam                            21.620   \n",
      "30             Al Horford                            21.120   \n",
      "28       Domantas Sabonis                            17.905   \n",
      "34         DeAndre Jordan                            17.360   \n",
      "36          D.J. Augustin                            14.420   \n",
      "31          Dwight Powell                            13.020   \n",
      "16           Steven Adams                            10.040   \n",
      "35          Tobias Harris                             9.070   \n",
      "37         Thaddeus Young                             5.800   \n",
      "33           Jerami Grant                             4.210   \n",
      "27          Jarrett Allen                             3.640   \n",
      "39       Bojan Bogdanovic                             3.540   \n",
      "\n",
      "    Neural Network Points Predictions  \\\n",
      "1                         1322.443132   \n",
      "0                         1297.799108   \n",
      "3                          765.862042   \n",
      "12                         471.317923   \n",
      "5                         1209.611288   \n",
      "6                          778.817539   \n",
      "11                         386.716002   \n",
      "18                         627.275356   \n",
      "2                          216.053131   \n",
      "4                         1116.841892   \n",
      "7                           60.773736   \n",
      "38                         886.278512   \n",
      "10                          57.078028   \n",
      "9                          186.291710   \n",
      "8                          234.729865   \n",
      "32                          37.249868   \n",
      "26                        -153.878357   \n",
      "15                         124.495822   \n",
      "14                          85.451274   \n",
      "17                          89.082439   \n",
      "21                        -104.049674   \n",
      "29                         -93.388582   \n",
      "25                         -60.578843   \n",
      "20                          22.391275   \n",
      "23                         212.758999   \n",
      "22                         132.685390   \n",
      "19                          85.511923   \n",
      "24                          96.158333   \n",
      "13                        -149.766557   \n",
      "30                         -58.601944   \n",
      "28                          92.379411   \n",
      "34                        -224.676891   \n",
      "36                          34.417989   \n",
      "31                         170.877406   \n",
      "16                         -71.610243   \n",
      "35                          95.370998   \n",
      "37                          40.038901   \n",
      "33                          76.571947   \n",
      "27                           2.392103   \n",
      "39                          39.659081   \n",
      "\n",
      "    Stochastic Gradient Descent Points Predictions  \n",
      "1                                       754.017659  \n",
      "0                                       795.309263  \n",
      "3                                       484.725728  \n",
      "12                                      288.860485  \n",
      "5                                       558.825526  \n",
      "6                                       448.492534  \n",
      "11                                      377.555392  \n",
      "18                                      367.764442  \n",
      "2                                       311.642691  \n",
      "4                                       310.710110  \n",
      "7                                       155.840866  \n",
      "38                                      410.736146  \n",
      "10                                       91.292475  \n",
      "9                                       330.432629  \n",
      "8                                       261.555602  \n",
      "32                                      190.252188  \n",
      "26                                      217.442300  \n",
      "15                                      319.043614  \n",
      "14                                      214.592624  \n",
      "17                                      112.131905  \n",
      "21                                      205.607458  \n",
      "29                                       33.809596  \n",
      "25                                       74.275434  \n",
      "20                                      204.047538  \n",
      "23                                       45.460415  \n",
      "22                                      228.558823  \n",
      "19                                       50.800533  \n",
      "24                                        6.989029  \n",
      "13                                      146.236938  \n",
      "30                                       61.045717  \n",
      "28                                       82.673467  \n",
      "34                                     -387.304983  \n",
      "36                                     -141.484756  \n",
      "31                                     -187.077799  \n",
      "16                                      -18.827255  \n",
      "35                                       52.737648  \n",
      "37                                      -90.388572  \n",
      "33                                     -149.501882  \n",
      "27                                     -101.072481  \n",
      "39                                     -113.090220  \n"
     ]
    }
   ],
   "source": [
    "# Test models against the 2018-19 season data to predict MVP\n",
    "# Random Forest Regressor\n",
    "best_rfr_pw_pred = best_rfr_pw.predict(test_data_scaled)\n",
    "\n",
    "# Neural Network\n",
    "best_nn_pw_pred = best_nn_pw.predict(test_data_scaled)\n",
    "\n",
    "# Stochastic Gradient Descent\n",
    "best_sgd_pw_pred = best_sgd_pw.predict(test_data_scaled)\n",
    "\n",
    "# Add predictions to the test data as columns\n",
    "test_data['Random Forest Points Predictions'] = best_rfr_pw_pred\n",
    "test_data['Neural Network Points Predictions'] = best_nn_pw_pred\n",
    "test_data['Stochastic Gradient Descent Points Predictions'] = best_sgd_pw_pred\n",
    "\n",
    "# Print results\n",
    "print(test_data[['player', \n",
    "                 'Random Forest Points Predictions', \n",
    "                 'Neural Network Points Predictions', \n",
    "                 'Stochastic Gradient Descent Points Predictions']].sort_values('Random Forest Points Predictions', \n",
    "                                                                                ascending = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting Total Vote Share for MVP Candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Models Performance (Award Share)\n",
      "Estimator:  50  | Mean Squared Error:  0.026498776674885937\n",
      "Estimator:  100  | Mean Squared Error:  0.025877537932709395\n",
      "Estimator:  200  | Mean Squared Error:  0.025475495629024653\n",
      "Estimator:  500  | Mean Squared Error:  0.024797095665827825\n",
      "Estimator:  1000  | Mean Squared Error:  0.024460382923049064\n",
      "------------------------------------------------------------- \n",
      "\n",
      "Neural Network Models Performance (Award Share)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer size:  50  | Alpha:  0.0001  | Mean Squared Error:  0.06222438530378529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer size:  50  | Alpha:  0.0003  | Mean Squared Error:  0.06447636133875162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer size:  50  | Alpha:  0.001  | Mean Squared Error:  0.05262862373786079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer size:  50  | Alpha:  0.003  | Mean Squared Error:  0.055169366837875544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer size:  100  | Alpha:  0.0001  | Mean Squared Error:  0.04203215704664216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer size:  100  | Alpha:  0.0003  | Mean Squared Error:  0.04252026822482413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer size:  100  | Alpha:  0.001  | Mean Squared Error:  0.04506435021636346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer size:  100  | Alpha:  0.003  | Mean Squared Error:  0.04470430854631221\n",
      "Layer size:  150  | Alpha:  0.0001  | Mean Squared Error:  0.03870058334192173\n",
      "Layer size:  150  | Alpha:  0.0003  | Mean Squared Error:  0.03982657212631944\n",
      "Layer size:  150  | Alpha:  0.001  | Mean Squared Error:  0.04133281722741805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer size:  150  | Alpha:  0.003  | Mean Squared Error:  0.040423315272221795\n",
      "Layer size:  200  | Alpha:  0.0001  | Mean Squared Error:  0.04685743080061438\n",
      "Layer size:  200  | Alpha:  0.0003  | Mean Squared Error:  0.046639791531100504\n",
      "Layer size:  200  | Alpha:  0.001  | Mean Squared Error:  0.047759359624096206\n",
      "Layer size:  200  | Alpha:  0.003  | Mean Squared Error:  0.048289706791704703\n",
      "Layer size:  250  | Alpha:  0.0001  | Mean Squared Error:  0.042140183764964215\n",
      "Layer size:  250  | Alpha:  0.0003  | Mean Squared Error:  0.039799577070629144\n",
      "Layer size:  250  | Alpha:  0.001  | Mean Squared Error:  0.041665647881003784\n",
      "Layer size:  250  | Alpha:  0.003  | Mean Squared Error:  0.040587140198458514\n",
      "------------------------------------------------------------- \n",
      "\n",
      "Stochastic Gradient Descent Models Performance (Award Share)\n",
      "Maximum iterations:  500  | Alpha:  0.0001  | Mean Squared Error:  0.02847753411245988\n",
      "Maximum iterations:  500  | Alpha:  0.0003  | Mean Squared Error:  0.027323304597229137\n",
      "Maximum iterations:  500  | Alpha:  0.001  | Mean Squared Error:  0.028352751636660768\n",
      "Maximum iterations:  500  | Alpha:  0.003  | Mean Squared Error:  0.028154841504948968\n",
      "Maximum iterations:  1000  | Alpha:  0.0001  | Mean Squared Error:  0.028681590903511217\n",
      "Maximum iterations:  1000  | Alpha:  0.0003  | Mean Squared Error:  0.028498588358989625\n",
      "Maximum iterations:  1000  | Alpha:  0.001  | Mean Squared Error:  0.027593849620175238\n",
      "Maximum iterations:  1000  | Alpha:  0.003  | Mean Squared Error:  0.028218264530940305\n",
      "Maximum iterations:  1500  | Alpha:  0.0001  | Mean Squared Error:  0.028039614335387396\n",
      "Maximum iterations:  1500  | Alpha:  0.0003  | Mean Squared Error:  0.02783315591555261\n",
      "Maximum iterations:  1500  | Alpha:  0.001  | Mean Squared Error:  0.02826049612539184\n",
      "Maximum iterations:  1500  | Alpha:  0.003  | Mean Squared Error:  0.028895990885829108\n",
      "Maximum iterations:  2000  | Alpha:  0.0001  | Mean Squared Error:  0.027431984346655745\n",
      "Maximum iterations:  2000  | Alpha:  0.0003  | Mean Squared Error:  0.027701191290240235\n",
      "Maximum iterations:  2000  | Alpha:  0.001  | Mean Squared Error:  0.028451991378936038\n",
      "Maximum iterations:  2000  | Alpha:  0.003  | Mean Squared Error:  0.028928126312118933\n",
      "Maximum iterations:  2500  | Alpha:  0.0001  | Mean Squared Error:  0.027912570602508645\n",
      "Maximum iterations:  2500  | Alpha:  0.0003  | Mean Squared Error:  0.027482557516645904\n",
      "Maximum iterations:  2500  | Alpha:  0.001  | Mean Squared Error:  0.028209694413606778\n",
      "Maximum iterations:  2500  | Alpha:  0.003  | Mean Squared Error:  0.027660666886317464\n"
     ]
    }
   ],
   "source": [
    "# Import libraries for modeling and evaluation\n",
    "from sklearn.linear_model import SGDRegressor # Stochastic Gradient Descent\n",
    "from sklearn.ensemble import RandomForestRegressor # Random Forest\n",
    "from sklearn.neural_network import MLPRegressor # Multi-layer perceptron network\n",
    "from sklearn.metrics import mean_squared_error # Metric used for model evaluation\n",
    "\n",
    "# Testing for best combination of parameters for Random Forest model\n",
    "estimators = [50, 100, 200, 500, 1000]\n",
    "print(\"Random Forest Models Performance (Award Share)\")\n",
    "for num_estimators in estimators:\n",
    "    print('Estimator: ', num_estimators, ' | Mean Squared Error: ', mse_random_forest(num_estimators, \n",
    "                                                                                      x_train_as,\n",
    "                                                                                      y_train_as, \n",
    "                                                                                      x_test_as, \n",
    "                                                                                      y_test_as))\n",
    "    \n",
    "print('-------------------------------------------------------------', '\\n')\n",
    "\n",
    "# Testing for best combination of parameters for Neural Network model\n",
    "layers = [50, 100, 150, 200, 250]\n",
    "alpha_test = [0.0001, 0.0003, 0.001, 0.003]\n",
    "print('Neural Network Models Performance (Award Share)')\n",
    "for num_hidden_layers in layers:\n",
    "    for alpha_used in alpha_test:\n",
    "        print('Layer size: ', num_hidden_layers, ' | Alpha: ', alpha_used, ' | Mean Squared Error: ',\n",
    "              mse_multi_layer_perceptron(num_hidden_layers, \n",
    "                                         alpha_used, \n",
    "                                         x_train_as, \n",
    "                                         y_train_as, \n",
    "                                         x_test_as, \n",
    "                                         y_test_as))\n",
    "        \n",
    "print('-------------------------------------------------------------', '\\n')\n",
    "\n",
    "# Testing for best combination of parameters for Stochastic Gradient Descent model\n",
    "max_iterations = [500, 1000, 1500, 2000, 2500]\n",
    "print('Stochastic Gradient Descent Models Performance (Award Share)')\n",
    "for iterations in max_iterations:\n",
    "    for alpha_used in alpha_test:\n",
    "        print('Maximum iterations: ', iterations, ' | Alpha: ', alpha_used, ' | Mean Squared Error: ',\n",
    "              mse_sgd(iterations,\n",
    "                      alpha_used, \n",
    "                      x_train_as, \n",
    "                      y_train_as, \n",
    "                      x_test_as,\n",
    "                      y_test_as))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
       "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
       "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=None,\n",
       "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting best models for each method\n",
    "# Random Forest Regressor\n",
    "best_rfr_as = RandomForestRegressor(n_estimators=1000, random_state=1)\n",
    "best_rfr_as.fit(x_train_as, y_train_as)\n",
    "\n",
    "# Neural Network\n",
    "best_nn_as = MLPRegressor(solver='lbfgs', hidden_layer_sizes=150, alpha=0.0001, random_state=1)\n",
    "best_nn_as.fit(x_train_as, y_train_as)\n",
    "\n",
    "# Stochastic Gradient Descent\n",
    "best_sgd_as = SGDRegressor(max_iter=1000, alpha=0.0001)\n",
    "best_sgd_as.fit(x_train_as, y_train_as)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   player  Random Forest Award Share Predictions  \\\n",
      "1   Giannis Antetokounmpo                               0.843771   \n",
      "0            James Harden                               0.774902   \n",
      "12          Kawhi Leonard                               0.670114   \n",
      "6            Kevin Durant                               0.617993   \n",
      "11          Stephen Curry                               0.605497   \n",
      "5            Nikola Jokic                               0.514549   \n",
      "3          Damian Lillard                               0.508508   \n",
      "2             Rudy Gobert                               0.340524   \n",
      "18            Joel Embiid                               0.310957   \n",
      "4             Paul George                               0.279204   \n",
      "38      Russell Westbrook                               0.237782   \n",
      "7            Clint Capela                               0.235065   \n",
      "8      Karl-Anthony Towns                               0.163901   \n",
      "9          Nikola Vucevic                               0.163073   \n",
      "15           Kyrie Irving                               0.157296   \n",
      "10         Andre Drummond                               0.143484   \n",
      "32           Kemba Walker                               0.117789   \n",
      "26           Jusuf Nurkic                               0.109187   \n",
      "14      LaMarcus Aldridge                               0.084909   \n",
      "17       Montrezl Harrell                               0.064710   \n",
      "25         Derrick Favors                               0.045317   \n",
      "29           Bradley Beal                               0.044657   \n",
      "23            Mike Conley                               0.042826   \n",
      "20            Ben Simmons                               0.041384   \n",
      "22          Blake Griffin                               0.040864   \n",
      "21           Eric Bledsoe                               0.038113   \n",
      "24           Jimmy Butler                               0.030293   \n",
      "31          Dwight Powell                               0.028605   \n",
      "28       Domantas Sabonis                               0.023395   \n",
      "19       Danilo Gallinari                               0.021930   \n",
      "36          D.J. Augustin                               0.021455   \n",
      "13          Pascal Siakam                               0.019356   \n",
      "34         DeAndre Jordan                               0.016841   \n",
      "30             Al Horford                               0.013555   \n",
      "16           Steven Adams                               0.013392   \n",
      "35          Tobias Harris                               0.010172   \n",
      "37         Thaddeus Young                               0.008459   \n",
      "27          Jarrett Allen                               0.004743   \n",
      "39       Bojan Bogdanovic                               0.004327   \n",
      "33           Jerami Grant                               0.003521   \n",
      "\n",
      "    Neural Network Award Share Predictions  \\\n",
      "1                                 1.456409   \n",
      "0                                 1.534397   \n",
      "12                                0.438482   \n",
      "6                                 0.686517   \n",
      "11                                0.457730   \n",
      "5                                 0.760833   \n",
      "3                                 0.765420   \n",
      "2                                 0.345769   \n",
      "18                                0.339389   \n",
      "4                                 0.698824   \n",
      "38                                0.496868   \n",
      "7                                 0.353118   \n",
      "8                                 0.126298   \n",
      "9                                 0.196022   \n",
      "15                                0.087474   \n",
      "10                                0.279620   \n",
      "32                               -0.025715   \n",
      "26                                0.068347   \n",
      "14                               -0.122466   \n",
      "17                                0.061263   \n",
      "25                               -0.064826   \n",
      "29                               -0.165299   \n",
      "23                                0.234330   \n",
      "20                               -0.046482   \n",
      "22                               -0.027752   \n",
      "21                                0.109204   \n",
      "24                               -0.002077   \n",
      "31                               -0.122532   \n",
      "28                                0.257311   \n",
      "19                                0.040558   \n",
      "36                                0.131084   \n",
      "13                               -0.263183   \n",
      "34                               -0.113348   \n",
      "30                                0.176476   \n",
      "16                                0.285439   \n",
      "35                                0.051462   \n",
      "37                                0.239498   \n",
      "27                               -0.052282   \n",
      "39                                0.073920   \n",
      "33                                0.068841   \n",
      "\n",
      "    Stochastic Gradient Descent Award Share Predictions  \n",
      "1                                            0.733138    \n",
      "0                                            0.714739    \n",
      "12                                           0.295344    \n",
      "6                                            0.409484    \n",
      "11                                           0.331910    \n",
      "5                                            0.528831    \n",
      "3                                            0.409324    \n",
      "2                                            0.344325    \n",
      "18                                           0.364266    \n",
      "4                                            0.297475    \n",
      "38                                           0.363531    \n",
      "7                                            0.188483    \n",
      "8                                            0.262694    \n",
      "9                                            0.307295    \n",
      "15                                           0.275802    \n",
      "10                                           0.127770    \n",
      "32                                           0.125621    \n",
      "26                                           0.228334    \n",
      "14                                           0.208036    \n",
      "17                                           0.113729    \n",
      "25                                           0.067655    \n",
      "29                                           0.010496    \n",
      "23                                          -0.009044    \n",
      "20                                           0.206038    \n",
      "22                                           0.166249    \n",
      "21                                           0.170645    \n",
      "24                                           0.033331    \n",
      "31                                          -0.175131    \n",
      "28                                           0.070024    \n",
      "19                                           0.040290    \n",
      "36                                          -0.173997    \n",
      "13                                           0.150813    \n",
      "34                                          -0.313780    \n",
      "30                                           0.058332    \n",
      "16                                           0.011489    \n",
      "35                                           0.049785    \n",
      "37                                          -0.081820    \n",
      "27                                          -0.077147    \n",
      "39                                          -0.118830    \n",
      "33                                          -0.149099    \n"
     ]
    }
   ],
   "source": [
    "# Test models against the 2018-19 season data to predict MVP\n",
    "# Random Forest Regressor\n",
    "best_rfr_as_pred = best_rfr_as.predict(test_data_scaled)\n",
    "\n",
    "# Neural Network\n",
    "best_nn_as_pred = best_nn_as.predict(test_data_scaled)\n",
    "\n",
    "# Stochastic Gradient Descent\n",
    "best_sgd_as_pred = best_sgd_as.predict(test_data_scaled)\n",
    "\n",
    "# Add predictions to the test data as columns\n",
    "test_data['Random Forest Award Share Predictions'] = best_rfr_as_pred\n",
    "test_data['Neural Network Award Share Predictions'] = best_nn_as_pred\n",
    "test_data['Stochastic Gradient Descent Award Share Predictions'] = best_sgd_as_pred\n",
    "\n",
    "# Print results\n",
    "print(test_data[['player', \n",
    "                 'Random Forest Award Share Predictions', \n",
    "                 'Neural Network Award Share Predictions', \n",
    "                 'Stochastic Gradient Descent Award Share Predictions']].sort_values('Random Forest Award Share Predictions', \n",
    "                                                                                ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
